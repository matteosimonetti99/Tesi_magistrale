Ti spiego il codice in poche parole così che tu possa procedere nell'impresa di lavorare su un codice scritto da qualcun'altro.
Ci sono 2 cartelle che sono 3.6 e 3.11, questo perchè una parte del codice è runnata in python 3.6 e la parte principale in 3.11.

La parte in 3.6 è stata fatta perchè il modulo di software chiamato bpmnParsing.py sfrutta una libreria chiamata bpmn_python (sempre nella cartella 3.6, l'ho scaricata perchè aveva un bug da patchare) che funziona solo fino a python 3.6. Nella cartella 3.11 invece c'è il main file che fa la simulazione tramite simpy che funziona solo con versioni + recenti di python, ecco perchè la doppia versione.

In 3.6 quindi c'è bpmnParsing che sfruttando bpmn_python legge il file bpmn e lo trasforma in un dizionario (salvato nella cartella json in bpmn.json), inoltre legge se c'è il tag <diagbp> nel bpmn, se non c'è cerca un file di configurazione extra chiamato diagbp.json nella cartella json, se non c'è nemmeno questo allora genera il tag chiedendo i parametri di simulazione (script diagbpTagGenerator.py) da linea di comando, per poi salvarli nel bpmn.

in 3.11 invece abbiamo parsingAgain che fa delle piccole modifiche extra semplici, timeCalculator che converte un dizionario con tipologia di tempo (fixed, normal, exponential...) e vari argomenti in un numero di secondi da usare come delay. Infine c'è main.py

Main.py ha la seguente struttura: all'inizio legge i file e setta delle variabili dai dati letti, poi c'è la class process, ogni classe rappresenta una pool (un partecipant) dell'istanza del processo bpmn (nome della classe un po' fuorviante). Quindi se ho un processo con 3 pool e voglio runnarlo per 5 volte, avrò 15 istanziazioni della classe process.
La classe ha varie funzioni ausiliari (per esempio run che viene chiamata per prima e trova lo start_node) ma la principale è run_node che viene chiamata in maniera ricorsiva, ogni volta che un nodo è stato letto ed eseguito, viene chiamata run_node sul successivo. run_node ha una lunga serie di if/elif che funzionano in base al tipo del nodo (start event, task, xor...), la zona più incasinata è quella dedicata a task, in quanto deve gestire worklists, cambio stampo (chiamato setup time), timetable checks (controllare se la risorsa è in shift), resource check (controllare se la risorsa è libera).
L'idea per le risorse è che ogni task può essere eseguita da vari gruppi di risorse, per esempio 1 clerk + 1 operaio oppure 3 clerks. Per ogni gruppo lo script controlla se ci sono abbastanza unità in timetable e available (se c'è una worklist attiva sulla task allora usa un subset delle risorse come punto di partenza), se si allora controlla se ci sono setup time da fare, altrimenti le blocca, fa il self.env.timeout del tempo della task e poi le rilascia.
La parte finale è per il log